{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f346595c",
   "metadata": {},
   "source": [
    "For dataset generation, in particular, use numpy-1.24.3, then uninstall/update numpy to latest model possible for image registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6330ac",
   "metadata": {},
   "source": [
    "Extracting random sample from class samples to form our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f1bee",
   "metadata": {},
   "source": [
    "output and input paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7af8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_root=Path(\"D:\\\\collegeCode\\\\sem4\\\\csd212_Project\\\\data\\\\raw\\\\CRC-VAL-HE-7K\")\n",
    "\n",
    "output_dir=Path(\"D:\\\\collegeCode\\\\sem4\\\\csd212_Project\\\\data\\\\sample_HE\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36a680",
   "metadata": {},
   "source": [
    "Getting all .tif images from source subfolders and sampling 1000 images randomly, then copying to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6a8420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7180 images.\n",
      "Copied 1000 images to 'D:\\collegeCode\\sem4\\csd212_Project\\data\\sample_HE\n"
     ]
    }
   ],
   "source": [
    "all_images=list(source_root.rglob(\"*.tif\"))\n",
    "print(f\"Found {len(all_images)} images.\")\n",
    "\n",
    "sample_size=1000\n",
    "sampled_images=random.sample(all_images, sample_size)\n",
    "\n",
    "for i, img_path in enumerate(sampled_images, start=1):\n",
    "    dest_path=output_dir/f\"{i:04d}.tif\"\n",
    "    shutil.copy(img_path, dest_path)\n",
    "\n",
    "print(f\"Copied {sample_size} images to '{output_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21719718",
   "metadata": {},
   "source": [
    "Data-PreProcessing\n",
    "As synthetic data has been generated and is being used, the below pre-processing steps are being skipped as inapplicable\n",
    "1. Rotation\n",
    "2. Scaling\n",
    "3. Translation\n",
    "4. Patch-based\n",
    "\n",
    "The following transformations have been applied\n",
    "1. Grayscale conversion\n",
    "2. Gaussian smoothing\n",
    "3. Elastic deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea77a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic dataset generated. \n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "input_dir=Path(\"D:\\\\collegeCode\\\\sem4\\\\csd212_Project\\\\data\\\\sample_HE\")\n",
    "output_root=Path(\"D:\\\\collegeCode\\\\sem4\\\\csd212_Project\\\\data\\\\synthetic_dataset\\\\train\")\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#elastic deformation operator\n",
    "elastic=iaa.ElasticTransformation(alpha=40, sigma=6)\n",
    "\n",
    "#looping through each HE image and processing it\n",
    "for idx, image_path in enumerate(sorted(input_dir.glob(\"*.tif\"))):\n",
    "    img=cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    img_resized=cv2.resize(img, (512, 384)) #as specified in paper\n",
    "\n",
    "    hsv=cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV).astype(np.float32)\n",
    "    hsv[:, :, 1]*=1.25 #boosts saturation\n",
    "    hsv[:, :, 2]*=0.9  #reduce brightness\n",
    "    hsv=np.clip(hsv, 0, 255).astype(np.uint8)\n",
    "    snapshot=cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    #add gaussian blur\n",
    "    snapshot=cv2.GaussianBlur(snapshot, (3, 3), 0)\n",
    "    noise=np.random.normal(0, 5, snapshot.shape).astype(np.uint8)\n",
    "    snapshot=cv2.add(snapshot, noise)\n",
    "\n",
    "    #elastic deformation\n",
    "    snapshot=elastic.augment_image(snapshot)\n",
    "\n",
    "    #convert both images to grayscale\n",
    "    snapshot_gray=cv2.cvtColor(snapshot, cv2.COLOR_BGR2GRAY)\n",
    "    he_gray=cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #applying CLAHE\n",
    "    clahe=cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    snapshot_gray=clahe.apply(snapshot_gray)\n",
    "    he_gray=clahe.apply(he_gray)\n",
    "\n",
    "    #saving HE and snapshots as PNGs\n",
    "    sample_dir=output_root/f\"sample_{idx:04d}\"\n",
    "    sample_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(str(sample_dir / \"he_target.png\"), he_gray)\n",
    "    cv2.imwrite(str(sample_dir / \"snapshot.png\"), snapshot_gray)\n",
    "\n",
    "print(\"Synthetic dataset generated. \")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
